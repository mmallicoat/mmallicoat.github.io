<!DOCTYPE html>
<html lang="en">
<head>
      <title>▲HEAP</title>
    <meta charset="utf-8" />
    <link rel="stylesheet" type="text/css" href="http://marshallmallicoat.com/theme/css/style.css" />
 <!-- adds article description to head, if available -->
</head>

<body>
  <header>
      <h1><a href="http://marshallmallicoat.com/" title="Home">▲HEAP</a></h1>
  </header>

  <main>
<article>
  <header><h1>Does the Computer Cheat in Mario Party?</h1></header>
  <footer>
        Revised
        <time class="modified" datetime="2018-11-18T00:00:00-06:00">
        18 Nov 2018</time>
  </footer>

  <div class="section" id="introduction">
<h2>Introduction</h2>
<p>I happened to play the video game <em>Mario Party 5</em> with my brother
over a holiday. The game involves rolling dice to move your
character around a playing board. Since we seemed to be getting
lower rolls on average than the computer players, we wondered if
perhaps they were given an advantage somehow. I manually recorded
a sample of the dice rolls from the game in order to test this
possibility.</p>
<p>The data and code for this project can be found on <a class="reference external" href="https://github.com/mmallicoat/mario-party">Github</a>.</p>
<!-- Style: Student's *t*-test; Mann–Whitney *U* test; Wilcoxon rank-sum test; (Pearson's) chi-squared test; Smirnov–Kolmogorov test; *p*-value -->
</div>
<div class="section" id="distribution-of-dice-rolls">
<h2>Distribution of Dice Rolls</h2>
<p>Each turn, a player rolls a die which returns an integer value
from 1 to 10. Naively, we would assume that the die behaves like
physical dice: that is, that each outcome is equally likely. <a class="footnote-reference" href="#id3" id="id1">[1]</a>
The chart below shows the frequencies of the outcomes for the
computer and human players from my sample.</p>
<div class="figure align-center">
<img alt="plot of dice roll frequencies" src="./figures/dice-outcome-frequencies.png" />
</div>
<p>Simply looking at the frequencies, it does seem that the computer
players tend to get more very high rolls (9s and 10s) than the
human players and that the human player get more very low rolls
(1s and 2s), but we must do a statistical test to make a rigorous
assessment. We need to perform a goodness of fit test to determine
if our sample likely comes from the assumed distribution: a
discrete uniform distribution with support on [1, 10].</p>
<p>A simple and effective goodness of fit test is the chi-squared
test. <a class="footnote-reference" href="#id4" id="id2">[2]</a> This compares the frequencies for each outcome to the
expected frequency under the null hypothesis that the outcomes are
equally likely. Performing the test, we get the following results:</p>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="39%" />
<col width="36%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Player</th>
<th class="head">Test Statistic</th>
<th class="head"><em>p</em>-value</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Human</td>
<td>6.000</td>
<td>0.740</td>
</tr>
<tr><td>Computer</td>
<td>5.973</td>
<td>0.743</td>
</tr>
</tbody>
</table>
<p>The <em>p</em>-values are much higher than any reasonable significance
level, so we cannot reject the assumption that the dice is fair
for both the computer and human players.</p>
<p>Since our sample size is somewhat small, around 40 samples for
each type of player, the expected frequency is around 4 for each
possible outcome. This is less than the rule of thumb that you
should have a minimum expectation of 5 in each category; so,
our test results may not be reliable. We can resolve this by
instead <em>pooling</em> the results into five categories of outcomes:
rolls of 1 or 2, 3 or 4, 5 or 6, 7 or 8, and 9 or 10. This gives
an expectation for each category of about 8, which should be
sufficient. The new results are then:</p>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="39%" />
<col width="36%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Player</th>
<th class="head">Test Statistic</th>
<th class="head"><em>p</em>-value</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Human</td>
<td>5.500</td>
<td>0.240</td>
</tr>
<tr><td>Computer</td>
<td>4.757</td>
<td>0.313</td>
</tr>
</tbody>
</table>
<p>The <em>p</em>-values are lower than previously, but the test is still
inconclusive. Both dice appear to be fair.</p>
<table class="docutils footnote" frame="void" id="id3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Additionally, we would expect each roll to be independent of
the others, but I have not tested this hypothesis.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[2]</a></td><td>I had first attempted to use the exact test of goodness of
fit. This requires evaluating the CDF of a multinomial
distribution. The CDF of the multinomial distribution
is simply the summation of the pmf evaluated at the
appropriate subset of the sample space. The size of the
sample space is given by a <a class="reference external" href="https://en.wikipedia.org/wiki/Stars_and_bars_(combinatorics)#Theorem_two">theorem in combinatorics</a>. The number of ways of arranging <em>n</em> objects into
<em>k</em> ordered partitions is <em>n + k - 1 choose n</em>. So, for a
10-dimensional multinomial distribution and a sample size of 40,
this is <em>49 choose 40</em>, or 2,054,455,634 combinations. To evaluate
the CDF at a particular value, a program would have to iterate
through a loop as many as 2 billion times, calculating the pmf
of one combination each time. Even using the <tt class="docutils literal">multiprocessing</tt>
library to take advantage of the two processor cores on my laptop,
I estimate this would take 5.5 hours. I don't think the additional
accuracy of the exact test over the chi-squared test is worth the
computational time.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="mean-dice-roll">
<h2>Mean Dice Roll</h2>
<p>Although we are unable to discern that the dice are anything but
fair, the mean dice roll for the computer players is 5.14, which
is slightly higher than the mean for the human players of 4.83.
Even if the outcomes of the dice rolls are close enough to fair
to avoid detection, there might still be some edge give to the
computer player. Instead of testing the distribution, we can
directly test whether the means of the two dice rolls are equal.</p>
<p>A common test of the means of two population is the Student's
<em>t</em>-test. This tests whether the difference of the means of the
two populations is significantly different than zero. The null
hypothesis is that the expected difference is exactly zero.</p>
<p>The results of this test show:</p>
<table border="1" class="docutils">
<colgroup>
<col width="52%" />
<col width="48%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Test Statistic</th>
<th class="head"><em>p</em>-value</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>0.496</td>
<td>0.621</td>
</tr>
</tbody>
</table>
<p>With this large <em>p</em>-value, we cannot reject the null hypothesis
that the means are equal.</p>
<p>The Student's <em>t</em>-test assumes that the means of the samples are
normally distributed. This will be true asymptotically, proven
in the Central Limit Theorem. <a class="footnote-reference" href="#id6" id="id5">[3]</a> Nevertheless, there exists
a nonparametric test which is almost as powerful as Student's
<em>t</em>-test in many contexts: the Mann–Whitney <em>U</em> test (also known
as the Wilcoxon sum-rank test). This tests the null hypothesis
that a random sample from one population is equally likely to
be greater than or less than a random sample from a second
population.</p>
<p>The results of the Mann–Whitney <em>U</em> test are:</p>
<table border="1" class="docutils">
<colgroup>
<col width="52%" />
<col width="48%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Test Statistic</th>
<th class="head"><em>p</em>-value</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>783.000</td>
<td>0.663</td>
</tr>
</tbody>
</table>
<p>Again, these are inconclusive. We cannot reject the hypothesis
that the means are equal.</p>
<table class="docutils footnote" frame="void" id="id6" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[3]</a></td><td>We have already assumed that the samples are independent,
but for the Central Limit Theorem to hold, the distribution of the
populations must also have finite variances. Since the outcomes of
the dice rolls are confined to the range [1, 10], this will be the
case.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="power-of-statistical-tests">
<h2>Power of Statistical Tests</h2>
<!-- Alternate title: Power Analysis -->
<p>It is possible to computer the <em>power</em> of a statistical test: the
probability of rejecting the null hypothesis given that the null
hypothesis is actually false. The power of a test is a function of
the sample size and the value of the distribution parameters under
the alternate hypothesis. By computing the power of a test, we can
get a sense of if our sample size is sufficiently large to perform
a maximally powerful test.</p>
<p>Below is a plot of the power curve of Student's <em>t</em>-test for
various sample sizes.</p>
<div class="figure align-center">
<img alt="plot of power curve for Student's t-test" src="./figures/students-t-power-curve.png" />
</div>
<p>We can see that, with a sample size of 77, our test is very
close the power curve of a test with a sample size of 1000.
Increasing the sample size of our test would only marginal
increase the power. Our sample size is large enough for performing
the Student's <em>t</em>-test at close to its maximum power. <a class="footnote-reference" href="#id8" id="id7">[4]</a></p>
<table class="docutils footnote" frame="void" id="id8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[4]</a></td><td>Student's <em>t</em> distribution is asymptotically normal as the
number of the degree of freedom approaches infinity. This is why we
see convergence in the power curves to some upper limit.</td></tr>
</tbody>
</table>
<!-- TODO: Plot power curve of chi-squared test as well -->
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>It seems that the dice in this game are fair and that no advantage
is given to either the computer or human players. Or, if either
of these is not the case, the deviation is small enough that our
tests are not powerful enough to detect it.</p>
<p>However, there are additional ways that the game may still bend
the rules that we have not tested. For example, if a player
had a run of low rolls, the game might increase the probably
of a higher rolls subsequently, in order to make the game more
forgiving. We could test the assumption that the rolls are indeed
independent of each other. There exist many <a class="reference external" href="https://en.wikipedia.org/wiki/Randomness_tests">tests of randomness</a> which can
discern &quot;non-randomness&quot; in a sample, even if the frequencies
of its outcomes match exactly the expected proportions.</p>
</div>


</article>
  </main>

  <hr>
  <footer>
  <nav>
    <h3>Navigation</h3>
    <ul>
      <li><a href="http://marshallmallicoat.com/">Home</a></li>
      <li><a href="http://marshallmallicoat.com/about.html">About</a></li>
      <li><a href="http://marshallmallicoat.com/feed.xml">Feed</a></li>
    </ul>
  </nav>
  </footer>
</body>
</html>